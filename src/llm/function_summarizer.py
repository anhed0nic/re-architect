"""
Function summarizer module for RE-Architect.

This module uses LLM-based techniques to generate human-readable summaries of decompiled functions.
"""

import logging
import json
import os
import time
import hashlib
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, asdict
from pathlib import Path

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

from src.core.config import Config
from src.analysis.enhanced_static_analyzer import FunctionInfo, Instruction

logger = logging.getLogger("re-architect.llm.summarizer")

@dataclass
class FunctionSummary:
    """Comprehensive summary of a function generated by LLM analysis."""
    name: str
    purpose: str
    behavior: str
    complexity_analysis: str
    arguments: List[Dict[str, str]]
    return_value: str
    side_effects: List[str]
    security_notes: List[str]
    optimization_suggestions: List[str]
    confidence_score: float
    analysis_method: str  # "enhanced" or "legacy"
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary representation."""
        return asdict(self)

@dataclass
class BatchSummaryResults:
    """Results from batch function summarization."""
    summaries: Dict[int, FunctionSummary]  # address -> summary
    total_functions: int
    successful_summaries: int
    failed_summaries: int
    total_time: float
    average_time_per_function: float

class FunctionSummarizer:
    """
    Advanced function summarizer for RE-Architect.
    
    This class uses language models to generate comprehensive, human-readable summaries 
    of binary functions using both static analysis data and decompiled code.
    """
    
    def __init__(self, config: Union[Dict, Config]):
        """
        Initialize the function summarizer.
        
        Args:
            config: Configuration object or dictionary
        """
        # Handle both Config objects and dictionaries
        if isinstance(config, dict):
            self.config = config
            self.provider = config.get("provider", "openai")
            self.model = config.get("model", "gpt-4")
            self.api_key = config.get("api_key")
            self.max_tokens = config.get("max_tokens", 4000)
            self.temperature = config.get("temperature", 0.2)
            self.cache_dir = config.get("cache_dir", "./cache/llm")
            self.use_cache = config.get("use_cache", True)
        else:
            self.config = config
            self.provider = config.get("llm.provider", "openai")
            self.model = config.get("llm.model", "gpt-4")
            self.api_key = config.get("llm.api_key")
            self.max_tokens = config.get("llm.max_tokens", 4000)
            self.temperature = config.get("llm.temperature", 0.2)
            self.cache_dir = config.get("llm.cache_dir", "./cache/llm")
            self.use_cache = config.get("llm.use_cache", True)
        
        # Create cache directory
        if self.use_cache:
            os.makedirs(self.cache_dir, exist_ok=True)
        
        # Initialize API client
        self._initialize_client()
        
        # In-memory cache for function summaries
        self._cache = {}
        
        # Statistics
        self.total_requests = 0
        self.cache_hits = 0
        
    def _initialize_client(self):
        """Initialize the appropriate LLM client."""
        self.client = None
        
        if not self.api_key:
            logger.warning("No API key provided - using mock responses for testing")
            return
            
        if self.provider == "openai" and OPENAI_AVAILABLE:
            try:
                self.client = openai.OpenAI(api_key=self.api_key)
                logger.info(f"Initialized OpenAI client with model {self.model}")
            except Exception as e:
                logger.error(f"Failed to initialize OpenAI client: {e}")
                
        elif self.provider == "anthropic" and ANTHROPIC_AVAILABLE:
            try:
                self.client = anthropic.Anthropic(api_key=self.api_key)
                logger.info(f"Initialized Anthropic client with model {self.model}")
            except Exception as e:
                logger.error(f"Failed to initialize Anthropic client: {e}")
        else:
            logger.warning(f"Provider '{self.provider}' not available or not installed")
        
    def analyze_function_enhanced(
        self, 
        func_info: FunctionInfo, 
        context: Optional[Dict[str, Any]] = None
    ) -> FunctionSummary:
        """
        Generate comprehensive analysis of a function using enhanced static analysis data.
        
        Args:
            func_info: Enhanced function information from static analysis
            context: Optional context information (call graph, binary info, etc.)
            
        Returns:
            Comprehensive function summary
        """
        logger.info(f"Analyzing function {func_info.name} with enhanced data")
        
        # Check cache first
        cache_key = self._get_cache_key_enhanced(func_info, context)
        if self.use_cache and cache_key in self._cache:
            self.cache_hits += 1
            return self._cache[cache_key]
        
        # Build analysis prompt
        prompt = self._build_enhanced_analysis_prompt(func_info, context)
        
        # Call LLM API
        try:
            response = self._call_llm_api(prompt)
            summary = self._parse_llm_response(response, func_info.name, "enhanced")
            
            # Cache result
            if self.use_cache:
                self._cache[cache_key] = summary
                
            self.total_requests += 1
            return summary
            
        except Exception as e:
            logger.error(f"Failed to analyze function {func_info.name}: {e}")
            return self._create_fallback_summary(func_info.name, "enhanced", str(e))
    
    def analyze_batch_enhanced(
        self, 
        functions: Dict[int, FunctionInfo], 
        context: Optional[Dict[str, Any]] = None,
        max_functions: Optional[int] = None
    ) -> BatchSummaryResults:
        """
        Perform batch analysis of multiple functions.
        
        Args:
            functions: Dictionary of address -> FunctionInfo
            context: Optional context information
            max_functions: Optional limit on number of functions to analyze
            
        Returns:
            Batch analysis results
        """
        start_time = time.time()
        
        # Limit functions if requested
        functions_to_analyze = dict(list(functions.items())[:max_functions]) if max_functions else functions
        
        logger.info(f"Starting batch analysis of {len(functions_to_analyze)} functions")
        
        summaries = {}
        successful = 0
        failed = 0
        
        for addr, func_info in functions_to_analyze.items():
            try:
                summary = self.analyze_function_enhanced(func_info, context)
                summaries[addr] = summary
                successful += 1
            except Exception as e:
                logger.error(f"Failed to analyze function at 0x{addr:x}: {e}")
                failed += 1
        
        total_time = time.time() - start_time
        avg_time = total_time / len(functions_to_analyze) if functions_to_analyze else 0
        
        logger.info(f"Batch analysis completed: {successful} successful, {failed} failed, {total_time:.2f}s total")
        
        return BatchSummaryResults(
            summaries=summaries,
            total_functions=len(functions_to_analyze),
            successful_summaries=successful,
            failed_summaries=failed,
            total_time=total_time,
            average_time_per_function=avg_time
        )
    
    def _build_enhanced_analysis_prompt(
        self, 
        func_info: FunctionInfo, 
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """Build a comprehensive analysis prompt using enhanced function data."""
        
        # Basic function information
        prompt = f"""Please analyze this binary function and provide a comprehensive summary.

FUNCTION INFORMATION:
Name: {func_info.name}
Address: 0x{func_info.address:08x}
Size: {func_info.size} bytes
Number of Instructions: {len(func_info.instructions)}
Complexity Score: {func_info.complexity:.1f}
Has Loops: {func_info.has_loops}
Entry Point: {func_info.entry_point}

DISASSEMBLED INSTRUCTIONS:
"""
        
        # Add first 20 instructions for analysis
        max_instructions = min(20, len(func_info.instructions))
        for i, insn in enumerate(func_info.instructions[:max_instructions]):
            prompt += f"  0x{insn.address:08x}: {insn.mnemonic} {insn.op_str}\n"
        
        if len(func_info.instructions) > max_instructions:
            prompt += f"  ... and {len(func_info.instructions) - max_instructions} more instructions\n"
        
        # Add function calls if available
        if func_info.calls:
            prompt += f"\nFUNCTION CALLS:\n"
            for call_addr in func_info.calls[:10]:  # Show first 10 calls
                prompt += f"  -> 0x{call_addr:08x}\n"
            if len(func_info.calls) > 10:
                prompt += f"  ... and {len(func_info.calls) - 10} more calls\n"
        
        # Add context if available
        if context:
            if "binary_info" in context:
                binary_info = context["binary_info"]
                prompt += f"\nBINARY CONTEXT:\n"
                prompt += f"  Format: {binary_info.format.value}\n"
                prompt += f"  Architecture: {binary_info.architecture.value}\n"
            
            if "strings" in context:
                relevant_strings = context["strings"][:5]  # Show first 5 strings
                if relevant_strings:
                    prompt += f"\nRELEVANT STRINGS:\n"
                    for addr, string in relevant_strings:
                        prompt += f"  \"{string}\"\n"
        
        prompt += """
ANALYSIS REQUEST:
Please provide a detailed analysis in the following JSON format:
{
    "purpose": "Brief description of what this function does",
    "behavior": "Detailed explanation of the function's behavior and logic flow",
    "complexity_analysis": "Analysis of why the complexity score is what it is",
    "arguments": [{"name": "arg1", "type": "int", "description": "description"}],
    "return_value": "Description of what the function returns",
    "side_effects": ["List of side effects like file I/O, memory allocation, etc."],
    "security_notes": ["Any potential security concerns or vulnerabilities"],
    "optimization_suggestions": ["Suggestions for code optimization if any"],
    "confidence_score": 0.85
}

Focus on:
1. Understanding the assembly instructions and their purpose
2. Identifying common patterns (loops, conditionals, function calls)
3. Determining the function's role in the larger program
4. Noting any security-relevant operations
5. Providing actionable insights for reverse engineering

Respond ONLY with the JSON object, no additional text."""
        
        return prompt
    def _call_llm_api(self, prompt: str) -> str:
        """Call the appropriate LLM API based on the provider."""
        try:
            if self.provider == "openai":
                return self._call_openai_api(prompt)
            elif self.provider == "anthropic":
                return self._call_anthropic_api(prompt)
            else:
                raise ValueError(f"Unsupported provider: {self.provider}")
        except Exception as e:
            logger.error(f"LLM API call failed: {e}")
            # Return mock response only if no client is available
            if not self.client:
                return self._get_mock_response()
            raise
    
    def _call_openai_api(self, prompt: str) -> str:
        """Call the OpenAI API to analyze a function."""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "You are an expert reverse engineer and binary analysis specialist. Analyze assembly code and provide detailed, accurate insights."
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                response_format={"type": "json_object"}
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            raise
    
    def _call_anthropic_api(self, prompt: str) -> str:
        """Call the Anthropic API to analyze a function."""
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                system="You are an expert reverse engineer and binary analysis specialist. Analyze assembly code and provide detailed, accurate insights. Always respond with valid JSON.",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
        except Exception as e:
            logger.error(f"Anthropic API error: {e}")
            raise
    
    def _parse_llm_response(self, response: str, function_name: str, method: str) -> FunctionSummary:
        """Parse the LLM response into a FunctionSummary object."""
        try:
            data = json.loads(response)
            
            return FunctionSummary(
                name=function_name,
                purpose=data.get("purpose", "Unknown purpose"),
                behavior=data.get("behavior", "Behavior analysis unavailable"),
                complexity_analysis=data.get("complexity_analysis", "Complexity analysis unavailable"),
                arguments=data.get("arguments", []),
                return_value=data.get("return_value", "Unknown return value"),
                side_effects=data.get("side_effects", []),
                security_notes=data.get("security_notes", []),
                optimization_suggestions=data.get("optimization_suggestions", []),
                confidence_score=data.get("confidence_score", 0.5),
                analysis_method=method
            )
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}")
            return self._create_fallback_summary(function_name, method, f"JSON parse error: {e}")
        except Exception as e:
            logger.error(f"Unexpected error parsing LLM response: {e}")
            return self._create_fallback_summary(function_name, method, f"Parse error: {e}")
    
    def _get_mock_response(self) -> str:
        """Return a mock response for testing without API access."""
        # For enhanced analysis, return JSON
        if hasattr(self, '_current_prompt') and 'JSON format' in self._current_prompt:
            return json.dumps({
                "purpose": "Function purpose analysis (mock mode - no API key provided)",
                "behavior": "Detailed behavior analysis would be provided by LLM with proper API access",
                "complexity_analysis": "Complexity analysis based on instruction count and control flow",
                "arguments": [],
                "return_value": "Return value analysis requires LLM API access",
                "side_effects": ["Mock analysis mode"],
                "security_notes": ["API key required for real security analysis"],
                "optimization_suggestions": ["Enable LLM API for optimization suggestions"],
                "confidence_score": 0.1
            })
        
        # For legacy analysis, return simple text
        return "This function performs basic operations and returns a result."
    
    def _create_fallback_summary(self, name: str, method: str, error: str) -> FunctionSummary:
        """Create a fallback summary when LLM analysis fails."""
        return FunctionSummary(
            name=name,
            purpose=f"Analysis failed: {error}",
            behavior="Unable to analyze behavior due to LLM error",
            complexity_analysis="Complexity analysis unavailable",
            arguments=[],
            return_value="Unknown",
            side_effects=["Analysis failed"],
            security_notes=[f"Security analysis failed: {error}"],
            optimization_suggestions=[],
            confidence_score=0.0,
            analysis_method=f"{method}_fallback"
        )
    
    def _get_cache_key_enhanced(self, func_info: FunctionInfo, context: Optional[Dict[str, Any]] = None) -> str:
        """Generate cache key for enhanced analysis."""
        # Create hash based on function content and relevant context
        content = f"{func_info.name}_{func_info.address}_{func_info.size}_{len(func_info.instructions)}"
        
        if context:
            # Only include serializable context elements
            context_key = ""
            if "function_count" in context:
                context_key += f"_fc_{context['function_count']}"
            if "strings" in context and context["strings"]:
                # Just include count of strings to avoid huge cache keys
                context_key += f"_sc_{len(context['strings'])}"
            if "binary_info" in context:
                binary_info = context["binary_info"]
                context_key += f"_bi_{binary_info.format.value}_{binary_info.architecture.value}"
            content += context_key
            
        return hashlib.md5(content.encode()).hexdigest()
    
    # Legacy methods for backward compatibility
    def summarize_function(self, function_code: str) -> str:
        """
        Legacy method for backward compatibility.
        Generate a basic summary for a function code string.
        """
        # Check cache
        cache_key = hashlib.md5(function_code.encode()).hexdigest()
        if self.use_cache and cache_key in self._cache and isinstance(self._cache[cache_key], str):
            self.cache_hits += 1
            return self._cache[cache_key]
            
        # Default behavior - create simple prompt for legacy code
        prompt = f"""Analyze this function code and provide a brief summary:

{function_code}

Respond with a single sentence describing what this function does."""
        
        try:
            response = self._call_llm_api(prompt)
            # For legacy method, just return the text response
            result = response.strip().replace('"', '')
            if self.use_cache:
                self._cache[cache_key] = result
            self.total_requests += 1
            return result
        except Exception as e:
            logger.error(f"Legacy analysis failed: {e}")
            return f"Function analysis failed: {e}"
    
    def summarize(self, function_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Legacy method for backward compatibility.
        Generate detailed information about a function from a dictionary.
        """
        return {
            "summary": f"Function {function_info.get('name', 'unknown')} analyzed via legacy method",
            "purpose": "Legacy analysis - upgrade to enhanced analysis for better results",
            "arguments": function_info.get('parameters', []),
            "return_value": function_info.get('return_type', 'unknown')
        }
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get summarizer statistics."""
        cache_hit_rate = (self.cache_hits / self.total_requests) if self.total_requests > 0 else 0
        return {
            "total_requests": self.total_requests,
            "cache_hits": self.cache_hits,
            "cache_hit_rate": cache_hit_rate,
            "provider": self.provider,
            "model": self.model,
            "cache_enabled": self.use_cache,
            "api_available": self.client is not None
        }
